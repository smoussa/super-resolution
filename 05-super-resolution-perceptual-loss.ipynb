{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.serialization import load_lua\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, models, datasets\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "matplotlib.rc('figure', figsize=(12, 5))\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_vec = torch.FloatTensor([ 0.485, 0.456, 0.406 ]).view(3,1,1)\n",
    "std_vec = torch.FloatTensor([ 0.229, 0.224, 0.225 ]).view(3,1,1)\n",
    "\n",
    "# convert tensor to image for viewing\n",
    "tensor_to_image = transforms.Compose([\n",
    "    transforms.ToPILImage()\n",
    "])\n",
    "\n",
    "def ycbcr_to_rgb(y, cb, cr):\n",
    "    # each arg is a 2D tensor\n",
    "    y = y.squeeze()\n",
    "    y = (y * 255.0).clamp(0, 255)\n",
    "    y = Image.fromarray(np.uint8(y), mode='L')\n",
    "    cb = transforms.ToPILImage()(cb).resize(y.size, Image.BICUBIC)\n",
    "    cr = transforms.ToPILImage()(cr).resize(y.size, Image.BICUBIC)\n",
    "    rgb = Image.merge('YCbCr', [y, cb, cr]).convert('RGB')\n",
    "    return transforms.ToTensor()(rgb)\n",
    "\n",
    "def normalise(x):\n",
    "    # x is an RGB tensor\n",
    "    return (x - mean_vec) / std_vec\n",
    "\n",
    "def denormalise(x):\n",
    "    # x is an RGB tensor\n",
    "    return x * std_vec + mean_vec\n",
    "\n",
    "def calculate_valid_crop_size(crop_size, upscale_factor):\n",
    "    return crop_size - (crop_size % upscale_factor)\n",
    "\n",
    "# create low resolution square images\n",
    "def input_transform(crop_size, upscale_factor):\n",
    "    return transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.Scale(crop_size // upscale_factor),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "# maintain high resolution square images\n",
    "def target_transform(crop_size):\n",
    "    return transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load each image as a duplicate pair\n",
    "class DoubleImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img_dir, input_transform=None, target_transform=None):\n",
    "        super(DoubleImageDataset, self).__init__()\n",
    "        \n",
    "        self.image_fnames = [os.path.join(img_dir, f) for f in os.listdir(img_dir)]\n",
    "        self.input_transform = input_transform\n",
    "        self.target_transform = target_transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # CAN MOVE THIS TO TRANSFORM COMPOSITION AS LAMBDA FN?\n",
    "        img = Image.open(self.image_fnames[index])\n",
    "        y_img, cb_img, cr_img = img.convert('YCbCr').split()\n",
    "        \n",
    "        y_low_res = self.input_transform(y_img)\n",
    "        cb_low_res = self.input_transform(cb_img)\n",
    "        cr_low_res = self.input_transform(cr_img)\n",
    "        \n",
    "        rgb_high_res = self.target_transform(img.convert('RGB'))\n",
    "        rgb_high_res = normalise(rgb_high_res) # note normalisation\n",
    "        y_high_res = self.target_transform(y_img)\n",
    "        \n",
    "        return y_low_res, cb_low_res, cr_low_res, rgb_high_res, y_high_res\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirname = '/home/samir/Downloads/ILSVRC2012_img_train/train'\n",
    "upscale_factor = 2\n",
    "crop_size = calculate_valid_crop_size(256, upscale_factor)\n",
    "\n",
    "train_dataset = DoubleImageDataset(\n",
    "    dirname,\n",
    "    input_transform=input_transform(crop_size, upscale_factor),\n",
    "    target_transform=target_transform(crop_size))\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=7,\n",
    "    pin_memory=True)\n",
    "\n",
    "# preview some images\n",
    "y_low_res, cb_low_res, cr_low_res, rgb_high_res, y_high_res = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "tensor_to_image(denormalise(rgb_high_res[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor_to_image(y_high_res[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor_to_image(y_low_res[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor_to_image(cb_low_res[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor_to_image(cr_low_res[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = ycbcr_to_rgb(y_low_res[idx], cb_low_res[idx], cr_low_res[idx])\n",
    "transforms.ToPILImage()(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UpsamplingNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, upscale_factor):\n",
    "        super(UpsamplingNetwork, self).__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(1, 64, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, upscale_factor**2, 3, padding=1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "        \n",
    "        self._initialise_weights()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pixel_shuffle(self.conv3(x))\n",
    "        return x\n",
    "    \n",
    "    def _initialise_weights(self):\n",
    "        gain = init.calculate_gain('relu')\n",
    "        init.orthogonal(self.conv1.weight, gain)\n",
    "        init.orthogonal(self.conv2.weight, gain)\n",
    "        init.orthogonal(self.conv3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "upsampling_net = UpsamplingNetwork(upscale_factor).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pretrained_model = models.vgg16(pretrained=True).features.cuda()\n",
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PerceptualLossNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, pretrained_model, extraction_layers, weights):\n",
    "        super(PerceptualLossNetwork, self).__init__()\n",
    "        \n",
    "        for param in pretrained_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        children = list(pretrained_model.children())\n",
    "        \n",
    "        modules = []\n",
    "        i = 0\n",
    "        for j, w in zip(extraction_layers, weights):\n",
    "            modules.append((nn.Sequential(*children[i:j+1]), w))\n",
    "            i = j+1\n",
    "        self.modules = modules\n",
    "        \n",
    "        self.loss_fn = nn.MSELoss()\n",
    "    \n",
    "    \n",
    "    def forward(self, x, target):\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        for module, weight in self.modules:\n",
    "            x = module(x)\n",
    "            target = module(target)\n",
    "            total_loss += self.loss_fn(x, target) * weight\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percept_net = PerceptualLossNetwork(\n",
    "    pretrained_model,\n",
    "    [29],\n",
    "    [1]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimiser = optim.Adam(upsampling_net.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "pixel_loss_fn = nn.MSELoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "print('Training ...')\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {:3d}/{:3d}'.format(epoch, num_epochs))\n",
    "\n",
    "    for i, batch in enumerate(data_loader, 1):\n",
    "        \n",
    "        y_low_res, cb_low_res, cr_low_res, rgb_high_res, y_high_res = batch\n",
    "        \n",
    "        y_low_res = Variable(y_low_res).cuda()\n",
    "        y_high_res = Variable(y_high_res).cuda()\n",
    "        rgb_high_res = Variable(rgb_high_res).cuda()\n",
    "        \n",
    "        optimiser.zero_grad()\n",
    "        \n",
    "        # upsample\n",
    "        y_high_res_pred = upsampling_net(y_low_res)\n",
    "        pixel_loss = pixel_loss_fn(y_high_res_pred, y_high_res)\n",
    "        \n",
    "        # convert prediction YCbCr to RGB\n",
    "        rgb_high_res_pred = []\n",
    "        for j, y_pred in enumerate(y_high_res_pred.cpu().data):\n",
    "            rgb_pred = ycbcr_to_rgb(y_pred, cb_low_res[j], cr_low_res[j])\n",
    "            rgb_high_res_pred.append(normalise(rgb_pred))\n",
    "        \n",
    "        rgb_high_res_pred = torch.stack(rgb_high_res_pred)\n",
    "        rgb_high_res_pred = Variable(rgb_high_res_pred.cuda())\n",
    "        \n",
    "        # compute perceptual loss\n",
    "        percept_loss = percept_net(rgb_high_res_pred, rgb_high_res)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = pixel_loss + percept_loss\n",
    "        loss.backward()\n",
    "        \n",
    "        optimiser.step()\n",
    "        \n",
    "        # if (i % 100 == 0):\n",
    "        print('#: {:3d} Losses: pixel: {:3f}, percept: {:3f}'.format(\n",
    "            i, pixel_loss.data[0], percept_loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "y_low_res, cb_low_res, cr_low_res, rgb_high_res, y_high_res = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor_to_image(y_low_res[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor_to_image(denormalise(rgb_high_res[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = upsampling_net(Variable(y_low_res[idx].unsqueeze(0)).cuda())\n",
    "prediction = prediction.cpu().data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transforms.ToPILImage()(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = ycbcr_to_rgb(prediction, cb_low_res[idx], cr_low_res[idx])\n",
    "transforms.ToPILImage()(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
